{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_split(dat,split_type, seed):\n",
    "    n_fold = 5\n",
    "    idx_test_fold = 0\n",
    "    idx_val_fold = -1\n",
    "    idx_test = None\n",
    "    idx_train = None\n",
    "    x_pep = dat.epi\n",
    "    x_tcr = dat.tcr\n",
    "    \n",
    "    if split_type == 'random':\n",
    "        pass\n",
    "    elif split_type == 'epi':\n",
    "        unique_peptides = np.unique(x_pep)\n",
    "        n_total = len(unique_peptides)\n",
    "    elif split_type == 'tcr':\n",
    "        unique_tcrs = np.unique(x_tcr)\n",
    "        n_total = len(unique_tcrs)\n",
    "        \n",
    "    np.random.seed(seed)    \n",
    "    idx_shuffled = np.arange(n_total)\n",
    "    np.random.shuffle(idx_shuffled)\n",
    "    \n",
    "    # Determine data split from folds\n",
    "    n_test = int(round(n_total / n_fold))\n",
    "    n_train = n_total - n_test\n",
    "\n",
    "    # Determine position of current test fold\n",
    "    test_fold_start_index = idx_test_fold * n_test\n",
    "    test_fold_end_index = (idx_test_fold + 1) * n_test\n",
    "\n",
    "    if split_type == 'random':\n",
    "        pass\n",
    "    elif split_type == 'epi':\n",
    "        if idx_val_fold < 0:\n",
    "            idx_test_pep = idx_shuffled[test_fold_start_index:test_fold_end_index]\n",
    "            test_peptides = unique_peptides[idx_test_pep]\n",
    "            idx_test = [index for index, pep in enumerate(x_pep) if pep in test_peptides]\n",
    "            idx_train = list(set(range(len(x_pep))).difference(set(idx_test)))\n",
    "        else:\n",
    "            pass\n",
    "    elif split_type == 'tcr':\n",
    "        if idx_val_fold < 0:\n",
    "            idx_test_tcr = idx_shuffled[test_fold_start_index:test_fold_end_index]\n",
    "            test_tcrs = unique_tcrs[idx_test_tcr]\n",
    "            idx_test = [index for index, tcr in enumerate(x_tcr) if tcr in test_tcrs]\n",
    "            idx_train = list(set(range(len(x_tcr))).difference(set(idx_test)))\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    testData = dat.iloc[idx_test, :].sample(frac=1).reset_index(drop=True)\n",
    "    trainData = dat.iloc[idx_train, :].sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    print('================check Overlapping========================')\n",
    "    print('number of overlapping tcrs: ', str(len(set(trainData.tcr).intersection(set(testData.tcr)))))\n",
    "    print('number of overlapping epitopes: ', str(len(set(trainData.epi).intersection(set(testData.epi)))))\n",
    "    \n",
    "    return trainData, testData\n",
    "\n",
    "\n",
    "def epi_token_tcr(df, name):\n",
    "#     df['epi_tcr'] = '<epi>' + df['epi'] + '<eoepi>' + '$' + '<tcr>' + df['tcr'] + '<eotcr>' + '<EOS>'\n",
    "    df['epi_tcr'] = df['epi'] + '$' + df['tcr'] + '<EOS>'\n",
    "    df['epi_tcr'].to_csv(f'./data/{name}.txt', header=False, index=False, sep='\\t')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================check Overlapping========================\n",
      "number of overlapping tcrs:  2920\n",
      "number of overlapping epitopes:  0\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('combined_dataset_repTCRs.csv')\n",
    "df = df[:150008] # only use positively bind pairs\n",
    "\n",
    "# Filter the dataframe to include only those epitopes with frequency > 100\n",
    "epitope_counts = df['epi'].value_counts()\n",
    "filtered_df = df[df['epi'].isin(epitope_counts[epitope_counts > 100].index)].reset_index(drop=True)\n",
    "\n",
    "#### writing training and testing data for different splits into disk\n",
    "trainData, testData = load_data_split(filtered_df, 'epi', 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ${EPI\\$TCR1[SEP]EPI\\$TCR2[SEP]EPI\\$TCR3[EOS]}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_k_shot_samples(df, name, k_shots, compact_format=False, seed=None):\n",
    "\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    epitope_groups = df.groupby('epi')['tcr'].apply(list)\n",
    "    all_k_shot_samples = []\n",
    "\n",
    "    # Iterate over each epitope group\n",
    "    for epitope, tcrs in epitope_groups.items():\n",
    "        total_tcrs = len(tcrs)\n",
    "\n",
    "        # Number of k-shot samples to create\n",
    "        num_samples = round(total_tcrs * 1.0) \n",
    "        num_samples = min(num_samples, len(tcrs) // k_shots)\n",
    "\n",
    "        for _ in range(num_samples):\n",
    "            # Sample k TCRs for this epitope, ensuring no duplicates\n",
    "            sampled_tcrs = np.random.choice(tcrs, k_shots, replace=False)\n",
    "\n",
    "            if compact_format:\n",
    "                # EPI$TCR1$TCR2$TCR3<EOS> format\n",
    "                k_shot_sample = f\"{epitope}${'$'.join(sampled_tcrs)}<EOS>\"\n",
    "            else:\n",
    "                # EPI$TCR1[SEP]EPI$TCR2[SEP]EPI$TCR3<EOS> format\n",
    "                k_shot_sample = '[SEP]'.join([f\"{epitope}${tcr}\" for tcr in sampled_tcrs]) + '<EOS>'\n",
    "\n",
    "            all_k_shot_samples.append(k_shot_sample)\n",
    "\n",
    "    # Saving the k-shot samples to a file\n",
    "    with open(f'{name}_{k_shots}_shot_samples_seed_{seed}.txt', 'w') as file:\n",
    "        for sample in all_k_shot_samples:\n",
    "            file.write(sample + '\\n')\n",
    "\n",
    "    # Indicating completion\n",
    "    print(f'{k_shots}-shot samples for {name} are saved to {name}_{k_shots}_shot_samples with seed {seed}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ${EPI\\$TCR1$TCR2$TCR3[EOS]}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-shot samples for training are saved to training_10_shot_samples with seed 99\n",
      "10-shot samples for testing are saved to testing_10_shot_samples with seed 99\n",
      "10-shot samples for training are saved to training_10_shot_samples with seed 73\n",
      "10-shot samples for testing are saved to testing_10_shot_samples with seed 73\n",
      "10-shot samples for training are saved to training_10_shot_samples with seed 42\n",
      "10-shot samples for testing are saved to testing_10_shot_samples with seed 42\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "# create_k_shot_samples(trainData, 'training', 3, compact_format=False)\n",
    "# create_k_shot_samples(testData, 'testing', 3, compact_format=False)\n",
    "\n",
    "create_k_shot_samples(trainData, 'training', 10, compact_format=True, seed=99)\n",
    "create_k_shot_samples(testData, 'testing', 10, compact_format=True, seed=99)\n",
    "\n",
    "create_k_shot_samples(trainData, 'training', 10, compact_format=True, seed=73)\n",
    "create_k_shot_samples(testData, 'testing', 10, compact_format=True, seed=73)\n",
    "\n",
    "create_k_shot_samples(trainData, 'training', 10, compact_format=True, seed=42)\n",
    "create_k_shot_samples(testData, 'testing', 10, compact_format=True, seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample TCRs with replacements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-shot samples for training are saved to training_10_shot_samples.txt\n",
      "10-shot samples for testing are saved to testing_10_shot_samples.txt\n",
      "5-shot samples for training are saved to training_5_shot_samples.txt\n",
      "5-shot samples for testing are saved to testing_5_shot_samples.txt\n",
      "3-shot samples for training are saved to training_3_shot_samples.txt\n",
      "3-shot samples for testing are saved to testing_3_shot_samples.txt\n"
     ]
    }
   ],
   "source": [
    "def create_k_shot_samples_w_replacement(df, name, k_shots, compact_format=False):\n",
    "    epitope_groups = df.groupby('epi')['tcr'].apply(list)\n",
    "    all_k_shot_samples = []\n",
    "\n",
    "    # Iterate over each epitope group\n",
    "    for epitope, tcrs in epitope_groups.items():\n",
    "        total_tcrs = len(tcrs)\n",
    "\n",
    "        # Number of k-shot samples to create\n",
    "        num_samples = round(total_tcrs * 1.0) \n",
    "        num_samples = min(num_samples, len(tcrs))\n",
    "\n",
    "        for _ in range(num_samples):\n",
    "            # Sample k TCRs for this epitope, ensuring no duplicates\n",
    "            sampled_tcrs = np.random.choice(tcrs, k_shots, replace=False)\n",
    "\n",
    "            if compact_format:\n",
    "                # EPI$TCR1$TCR2$TCR3<EOS> format\n",
    "                k_shot_sample = f\"{epitope}${'$'.join(sampled_tcrs)}<EOS>\"\n",
    "            else:\n",
    "                # EPI$TCR1[SEP]EPI$TCR2[SEP]EPI$TCR3<EOS> format\n",
    "                k_shot_sample = '[SEP]'.join([f\"{epitope}${tcr}\" for tcr in sampled_tcrs]) + '<EOS>'\n",
    "\n",
    "            all_k_shot_samples.append(k_shot_sample)\n",
    "\n",
    "    # Saving the k-shot samples to a file\n",
    "    with open(f'{name}_{k_shots}_shot_samples.txt', 'w') as file:\n",
    "        for sample in all_k_shot_samples:\n",
    "            file.write(sample + '\\n')\n",
    "\n",
    "    # Indicating completion\n",
    "    print(f'{k_shots}-shot samples for {name} are saved to {name}_{k_shots}_shot_samples.txt')\n",
    "\n",
    "# Example usage\n",
    "create_k_shot_samples_w_replacement(trainData, 'training', 10, compact_format=False)\n",
    "create_k_shot_samples_w_replacement(testData, 'testing', 10, compact_format=False)\n",
    "\n",
    "create_k_shot_samples_w_replacement(trainData, 'training', 5, compact_format=False)\n",
    "create_k_shot_samples_w_replacement(testData, 'testing', 5, compact_format=False)\n",
    "\n",
    "create_k_shot_samples_w_replacement(trainData, 'training', 3, compact_format=False)\n",
    "create_k_shot_samples_w_replacement(testData, 'testing', 3, compact_format=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-shot samples for training are saved to training_10_shot_samples.txt\n",
      "10-shot samples for testing are saved to testing_10_shot_samples.txt\n",
      "5-shot samples for training are saved to training_5_shot_samples.txt\n",
      "5-shot samples for testing are saved to testing_5_shot_samples.txt\n",
      "3-shot samples for training are saved to training_3_shot_samples.txt\n",
      "3-shot samples for testing are saved to testing_3_shot_samples.txt\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "create_k_shot_samples_w_replacement(trainData, 'training', 10, compact_format=True)\n",
    "create_k_shot_samples_w_replacement(testData, 'testing', 10, compact_format=True)\n",
    "\n",
    "create_k_shot_samples_w_replacement(trainData, 'training', 5, compact_format=True)\n",
    "create_k_shot_samples_w_replacement(testData, 'testing', 5, compact_format=True)\n",
    "\n",
    "create_k_shot_samples_w_replacement(trainData, 'training', 3, compact_format=True)\n",
    "create_k_shot_samples_w_replacement(testData, 'testing', 3, compact_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mygpt",
   "language": "python",
   "name": "mygpt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
